name: Daily Microsoft & Meta Jobs Scraper

on:
  schedule:
    - cron: '0 7 * * *'
  workflow_dispatch:

permissions:
  contents: write
  actions: read

jobs:
  scrape-jobs:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install Python deps (new Selenium)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install "selenium>=4.25"

      # 1) Remove any preinstalled/stale chromedriver from PATH
      - name: Remove preinstalled chromedriver
        run: |
          set -eux
          for p in /usr/local/bin/chromedriver /usr/bin/chromedriver /usr/local/share/chromedriver-linux64/chromedriver; do
            sudo rm -f "$p" || true
          done
          # Show what (if anything) remains
          command -v chromedriver || true

      # 2) Install Chrome stable
      - name: Set up Chrome
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: stable

      # 3) Install a matching Chromedriver for that Chrome
      - name: Set up Chromedriver (match Chrome)
        uses: browser-actions/setup-chromedriver@v1
        with:
          chrome-version: stable

      # Optional: verify versions & which driver is used
      - name: Show versions
        run: |
          google-chrome --version
          which chromedriver
          chromedriver --version

      - name: Run Microsoft job scraper
        run: python ms_jobs_daily_scraper.py

      - name: Run Meta job scraper
        run: python meta_jobs_daily_scraper.py

      - name: Configure Git
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

      - name: Check for changes
        id: git-check
        run: |
          git add .
          if git diff --staged --quiet; then
            echo "changes=false" >> $GITHUB_OUTPUT
          else
            echo "changes=true" >> $GITHUB_OUTPUT
          fi

      - name: Commit and push changes
        if: steps.git-check.outputs.changes == 'true'
        run: |
          git commit -m "ðŸ¤– Daily job scraping update - $(date +'%Y-%m-%d %H:%M UTC')"
          git push

      - name: Create summary
        if: always()
        run: | 
          # (your existing summary python here unchanged)

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: job-scraping-results-${{ github.run_number }}
          path: |
            Microsoft-jobs/ms_job_ids.json
            Microsoft-jobs/ms_job_details.json
            Microsoft-jobs/ms_job_avoid_hits_by_field.json
            Microsoft-jobs/jobs_by_date/
            Meta-jobs/meta_job_ids.json
            Meta-jobs/meta_job_details.json
            Meta-jobs/jobs_by_date/
          retention-days: 30

      - name: Notify on failure
        if: failure()
        run: |
          {
            echo "âŒ Job scraping failed. Check the logs for details."
            echo
            echo "**Possible issues:**"
            echo "- Website structure changes"
            echo "- Network connectivity issues"
            echo "- Chrome/Selenium compatibility issues"
            echo "- Rate limiting from the target website"
          } >> "$GITHUB_STEP_SUMMARY"
